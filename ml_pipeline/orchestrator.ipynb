{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"orchestrator.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Pipeline Workflow\n","\n","This noteboook includes the workflow for both processes:\n","1. Data Pipeline\n","2. Model Pipeline\n","\n","TODO:\n","- @All align on the python files/naming conventions and each steps\n","- @All make sure the steps reflect the one Fred proposed"],"metadata":{"id":"d3ZkjF-yw6We"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JZGmt1OuwdLb","executionInfo":{"status":"ok","timestamp":1653929929779,"user_tz":420,"elapsed":42313,"user":{"displayName":"Tia Burton","userId":"09352393735441630552"}},"outputId":"057d4f58-57b0-4b99-e611-da0992629a75"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd \"/content/drive/Shareddrives/SIADS - 694-695 Team Drive/python-files\"\n","!ls -l"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pYasLeTo5BIq","executionInfo":{"status":"ok","timestamp":1653930144922,"user_tz":420,"elapsed":1076,"user":{"displayName":"Tia Burton","userId":"09352393735441630552"}},"outputId":"d137f02a-6490-4026-9118-d4dc293989e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/SIADS - 694-695 Team Drive/python-files\n","total 184\n","-rw------- 1 root root 11560 May 30 17:02 a1_likelihood_model.py\n","-rw------- 1 root root  1123 May 30 16:37 a1_model_inference.py\n","-rw------- 1 root root  1086 May 30 16:04 a1_model_training.py\n","-rw------- 1 root root  1073 May 30 16:04 a2_model_inference.py\n","-rw------- 1 root root  1076 May 30 16:03 a2_model_training.py\n","-rw------- 1 root root 47838 May 25 19:39 B2_B1_clustering_code.py\n","-rw------- 1 root root 47276 May 25 20:27 B2_B1_model_training.py\n","-rw------- 1 root root  1577 May 20 00:04 clean_dataset.py\n","-rw------- 1 root root  2434 May 12 00:19 create_sample_dataset.py\n","-rw------- 1 root root  2988 May 15 00:57 data_extraction.py\n","-rw------- 1 root root 20393 May 26 15:25 data_prep.py\n","-rw------- 1 root root     0 Apr 23 23:30 data_preprocessing.py\n","-rw------- 1 root root  1005 May 20 00:44 data_vis.py\n","-rw------- 1 root root 24216 May 30 16:59 orchestrator.ipynb\n","drwx------ 2 root root  4096 May 11 04:15 __pycache__\n","-rw------- 1 root root   910 May 30 16:53 requirements.txt\n","-rw------- 1 root root 10931 May 30 15:47 transaction_extraction.py\n","-rw------- 1 root root  4130 May 12 00:15 utils.py\n"]}]},{"cell_type":"code","source":["!python --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S5zc5gw9wnxZ","executionInfo":{"status":"ok","timestamp":1653925393199,"user_tz":240,"elapsed":316,"user":{"displayName":"Idris Hanafi","userId":"08993226175925256732"}},"outputId":"dc979f2b-6345-4b15-9650-37339d3e3816"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.7.13\n"]}]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vdte_ZkxXH1b","executionInfo":{"status":"ok","timestamp":1653937893403,"user_tz":240,"elapsed":5414,"user":{"displayName":"Idris Hanafi","userId":"08993226175925256732"}},"outputId":"cad4d636-6799-4f56-9a13-a9978f02ff40"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting https://github.com/pandas-profiling/pandas-profiling/archive/master.zip (from -r requirements.txt (line 9))\n","  Using cached https://github.com/pandas-profiling/pandas-profiling/archive/master.zip (21.8 MB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.3.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.21.6)\n","Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.18.1)\n","Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.1)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.0)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (5.5.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (0.11.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (3.2.2)\n","Requirement already satisfied: folium==0.2.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.2.1)\n","Requirement already satisfied: markupsafe==2.0.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (2.0.1)\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (0.8.1)\n","Requirement already satisfied: scikit-learn-extra in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (0.2.0)\n","Requirement already satisfied: factor_analyzer in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (0.4.0)\n","Requirement already satisfied: category_encoders in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (2.4.1)\n","Requirement already satisfied: s-dbw in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (0.4.0)\n","Requirement already satisfied: prince in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (0.7.1)\n","Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (4.2.0)\n","Requirement already satisfied: pickle5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 23)) (0.0.12)\n","Collecting pyyaml==5.4.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 9.1 MB/s \n","\u001b[?25hRequirement already satisfied: joblib~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==3.2.0->-r requirements.txt (line 9)) (1.1.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==3.2.0->-r requirements.txt (line 9)) (1.7.3)\n","Requirement already satisfied: pydantic>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==3.2.0->-r requirements.txt (line 9)) (1.9.1)\n","Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==3.2.0->-r requirements.txt (line 9)) (2.11.3)\n","Requirement already satisfied: visions[type_image_path]==0.7.5 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==3.2.0->-r requirements.txt (line 9)) (0.7.5)\n","Requirement already satisfied: htmlmin>=0.1.12 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==3.2.0->-r requirements.txt (line 9)) (0.1.12)\n","Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==3.2.0->-r requirements.txt (line 9)) (0.5.1)\n","Requirement already satisfied: phik>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==3.2.0->-r requirements.txt (line 9)) (0.12.2)\n","Requirement already satisfied: tangled-up-in-unicode==0.2.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==3.2.0->-r requirements.txt (line 9)) (0.2.0)\n","Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==3.2.0->-r requirements.txt (line 9)) (2.27.1)\n","Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==3.2.0->-r requirements.txt (line 9)) (4.64.0)\n","Requirement already satisfied: multimethod>=1.4 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==3.2.0->-r requirements.txt (line 9)) (1.8)\n","Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.5->pandas-profiling==3.2.0->-r requirements.txt (line 9)) (21.4.0)\n","Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.5->pandas-profiling==3.2.0->-r requirements.txt (line 9)) (2.6.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.5->pandas-profiling==3.2.0->-r requirements.txt (line 9)) (7.1.2)\n","Requirement already satisfied: imagehash in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.5->pandas-profiling==3.2.0->-r requirements.txt (line 9)) (4.2.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 1)) (2022.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 8)) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 8)) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.4.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->-r requirements.txt (line 8)) (4.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 1)) (1.15.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling==3.2.0->-r requirements.txt (line 9)) (1.26.9)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling==3.2.0->-r requirements.txt (line 9)) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling==3.2.0->-r requirements.txt (line 9)) (2022.5.18.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling==3.2.0->-r requirements.txt (line 9)) (2.10)\n","Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->-r requirements.txt (line 3)) (1.0.3)\n","Requirement already satisfied: google-auth>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->-r requirements.txt (line 3)) (1.35.0)\n","Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->-r requirements.txt (line 3)) (0.4.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage->-r requirements.txt (line 3)) (4.2.4)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage->-r requirements.txt (line 3)) (57.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage->-r requirements.txt (line 3)) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage->-r requirements.txt (line 3)) (0.2.8)\n","Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->-r requirements.txt (line 3)) (1.31.5)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->-r requirements.txt (line 3)) (3.17.3)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->-r requirements.txt (line 3)) (1.56.1)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->-r requirements.txt (line 3)) (21.3)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2.0->google-cloud-storage->-r requirements.txt (line 3)) (0.4.8)\n","Requirement already satisfied: py4j==0.10.9.3 in /usr/local/lib/python3.7/dist-packages (from pyspark->-r requirements.txt (line 4)) (0.10.9.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->-r requirements.txt (line 5)) (1.0.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->-r requirements.txt (line 6)) (8.0.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 5)) (3.1.0)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders->-r requirements.txt (line 16)) (0.10.2)\n","Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders->-r requirements.txt (line 16)) (0.5.2)\n","Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.7/dist-packages (from selenium->-r requirements.txt (line 22)) (0.9.2)\n","Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.7/dist-packages (from selenium->-r requirements.txt (line 22)) (0.20.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->-r requirements.txt (line 22)) (1.2.0)\n","Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->-r requirements.txt (line 22)) (1.10)\n","Requirement already satisfied: outcome in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->-r requirements.txt (line 22)) (1.1.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->-r requirements.txt (line 22)) (2.4.0)\n","Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.7/dist-packages (from trio-websocket~=0.9->selenium->-r requirements.txt (line 22)) (1.1.0)\n","Requirement already satisfied: cryptography>=1.3.4 in /usr/local/lib/python3.7/dist-packages (from urllib3<1.27,>=1.21.1->requests>=2.24.0->pandas-profiling==3.2.0->-r requirements.txt (line 9)) (37.0.2)\n","Requirement already satisfied: pyOpenSSL>=0.14 in /usr/local/lib/python3.7/dist-packages (from urllib3<1.27,>=1.21.1->requests>=2.24.0->pandas-profiling==3.2.0->-r requirements.txt (line 9)) (22.0.0)\n","Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3<1.27,>=1.21.1->requests>=2.24.0->pandas-profiling==3.2.0->-r requirements.txt (line 9)) (1.7.1)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3<1.27,>=1.21.1->requests>=2.24.0->pandas-profiling==3.2.0->-r requirements.txt (line 9)) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3<1.27,>=1.21.1->requests>=2.24.0->pandas-profiling==3.2.0->-r requirements.txt (line 9)) (2.21)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->-r requirements.txt (line 22)) (0.13.0)\n","Requirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from imagehash->visions[type_image_path]==0.7.5->pandas-profiling==3.2.0->-r requirements.txt (line 9)) (1.3.0)\n","Installing collected packages: pyyaml\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 6.0\n","    Uninstalling PyYAML-6.0:\n","      Successfully uninstalled PyYAML-6.0\n","Successfully installed pyyaml-5.4.1\n"]}]},{"cell_type":"markdown","source":["If you need a library that's not built into Colab's environment, you can add them as follows:"],"metadata":{"id":"AO22Rtci52aU"}},{"cell_type":"code","source":["## installing relevant packages\n","# !pip install google-search-results package2 package3 ...\n","# !pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip --quiet\n","# !pip install markupsafe~=2.1.1 --quiet\n","# !pip install folium==0.2.1 --quiet\n","# !pip install markupsafe==2.0.1 --quiet\n","# !pip install imbalanced-learn --quiet\n","# !pip install scikit-learn-extra --quiet\n","# !pip install factor_analyzer --quiet\n","# !pip install --upgrade category_encoders --quiet\n","# !pip install --upgrade s-dbw --quiet\n","# !pip install imbalanced-learn --quiet\n","# !pip install scikit-learn-extra --quiet\n","# !pip install factor_analyzer --quiet\n","# !pip install prince --quiet\n","# !pip install selenium --quiet\n","# !pip install pickle5 --quiet\n","# !pip install pyspark --quiet\n","# !pip install plotly --quiet\n","# !pip install pyyaml==5.4.1"],"metadata":{"id":"HqTeM9Fs5zTV","executionInfo":{"status":"ok","timestamp":1653938113935,"user_tz":240,"elapsed":153,"user":{"displayName":"Idris Hanafi","userId":"08993226175925256732"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["### Step 1: Data Extraction Portion\n","\n","Goal for this step: \n","- Pull from BigQuery and generate 6 months frozen dataset\n","\n","TODO: \n","- [x] @Tia to refactor the extraction to reflect the notebook: `Data_Processing.ipynb`\n","- [Optional] @Tia refine dates logic to be customizable\n","- [x] @Tia add argparse\n"],"metadata":{"id":"ypwxLHiYw1g8"}},{"cell_type":"code","source":["!python data_extraction.py \\\n","  --output_directory ../datasets/monthly-partitioned-data/ \\\n","  --credentials_json ../credentials/compact-scene-317315-56e479e9e148.json"],"metadata":{"id":"yss61KQWwwIZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 2: Transaction Extraction Portion\n","\n","**WARNING: THIS TAKES ~12 HOURS TO RUN**\n","\n","Goal:\n","- Pull all Transactions from monthly datasets from Step 1\n","- Pull all Non-Transactions from monthly datasets from Step 1\n","\n","TODO: \n","- [x] @Idris to refactor the extraction to reflect the notebook and pull all transactions from each monthly dataset: `Extraction_Data_Sample.ipynb`\n","- [x] @Idris add argparse\n"],"metadata":{"id":"f1UoZwT9xZ_K"}},{"cell_type":"code","source":["%%time\n","!python transaction_extraction.py \\\n","  --input_directory ../datasets/monthly_partitioned_data/ \\\n","  --output_directory ../datasets/monthly_partitioned_data_transactions/"],"metadata":{"id":"6Y-vxJUrn12f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 3: Data Sampling Portion\n","\n","Goal:\n","1. Reads all transactions CSV from the input directory and join as one DF.\n","2. Reads all non-transactions CSV from the input directory and samples 10%\n","3. Join both results from Step 1 and 2 into one DF called `sample_dataset.csv`\n","\n","TODO: \n","- [x] @Idris to refactor the extraction to reflect the notebook: `Data_Processing.ipynb`\n","- [x] @Idris add argparse\n"],"metadata":{"id":"d5d9FHOn0MSu"}},{"cell_type":"code","source":["%%time\n","!python create_sample_dataset.py \\\n","  --input_directory ../datasets/monthly_partitioned_data_transactions/ \\\n","  --output_file ../datasets/sample_dataset.csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UxRpydk80LR2","executionInfo":{"status":"ok","timestamp":1652315448363,"user_tz":240,"elapsed":363178,"user":{"displayName":"Idris Hanafi","userId":"08993226175925256732"}},"outputId":"bc3f2555-5b10-4625-d63e-b41bb0debb60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["../datasets/monthly_partitioned_data_transactions/ ../datasets/sample_dataset.csv\n","['../datasets/monthly_partitioned_data_transactions/non_transactions/non_transactions_from_January 2017 Google Analytics Dataset.csv', '../datasets/monthly_partitioned_data_transactions/non_transactions/non_transactions_from_August 2016 Google Analytics Dataset.csv', '../datasets/monthly_partitioned_data_transactions/non_transactions/non_transactions_from_September 2016 Google Analytics Dataset.csv', '../datasets/monthly_partitioned_data_transactions/non_transactions/non_transactions_from_October 2016 Google Analytics Dataset.csv', '../datasets/monthly_partitioned_data_transactions/non_transactions/non_transactions_from_November 2016 Google Analytics Dataset.csv', '../datasets/monthly_partitioned_data_transactions/non_transactions/non_transactions_from_December 2016 Google Analytics Dataset.csv']\n","100% 6/6 [03:32<00:00, 35.37s/it]\n","CPU times: user 2.91 s, sys: 595 ms, total: 3.5 s\n","Wall time: 6min 2s\n"]}]},{"cell_type":"markdown","source":["### Step 4: Common Data Cleaning & Descriptive Analysis Portion\n","\n","Goal:\n","- Drop unneeded columns (Refer to this [link](https://docs.google.com/spreadsheets/d/1fT-iZyGZnpkli9ve9EY9TRTfycNlIoxp/edit?usp=sharing&ouid=116636835356831800242&rtpof=true&sd=true))\n","- Cast to appropriate datatypes\n","\n","On a different notebook:\n","- Visualizations\n","- EDA\n","- Describing Data\n","- Histograms\n","- Dashboarding ([Pandas Profiling](https://github.com/ydataai/pandas-profiling))\n","\n","Assigned: \n","- [x] @Tia\n"],"metadata":{"id":"UA0knB0k1Dov"}},{"cell_type":"code","source":["!python clean_dataset.py \\\n","  --input_file ../datasets/sample_dataset.csv \\\n","  --output_file ../datasets/cleaned_dataset.csv \\\n","  --dashboard_file ../datasets/dashboard_files/cleaned_dataset_dashboard.html"],"metadata":{"id":"fRLHvfl22Cx-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653938058652,"user_tz":240,"elapsed":150960,"user":{"displayName":"Idris Hanafi","userId":"08993226175925256732"}},"outputId":"1ac85887-55fc-4406-e0ad-c024ffbd75eb"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["tcmalloc: large alloc 1073741824 bytes == 0x45676000 @  0x7f11dc7972a4 0x7f11ca9999a5 0x7f11ca99acc1 0x7f11ca99c69e 0x7f11ca96d50c 0x7f11ca97a399 0x7f11ca96297a 0x59afff 0x515655 0x549e0e 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x5118f8 0x549576 0x4bcb19 0x5134a6 0x549e0e 0x593fce 0x548ae9 0x51566f 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e\n","tcmalloc: large alloc 2147483648 bytes == 0x95e82000 @  0x7f11dc7972a4 0x7f11ca9999a5 0x7f11ca99acc1 0x7f11ca99c69e 0x7f11ca96d50c 0x7f11ca97a399 0x7f11ca96297a 0x59afff 0x515655 0x549e0e 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x5118f8 0x549576 0x4bcb19 0x5134a6 0x549e0e 0x593fce 0x548ae9 0x51566f 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e\n","Summarize dataset:  19% 10/54 [00:03<00:17,  2.58it/s, Describe variable:customDimensions]tcmalloc: large alloc 592826335232 bytes == 0x1381ee000 @  0x7f11dc798001 0x7f11da1271af 0x7f11da1815f4 0x7f11da216841 0x5936cc 0x548c51 0x5127f1 0x549576 0x593fce 0x511e2c 0x593dd7 0x5118f8 0x549e0e 0x593fce 0x5118f8 0x549e0e 0x4bcb19 0x5134a6 0x549576 0x4bcb19 0x532e76 0x595ef6 0x5134a6 0x549e0e 0x4bcb19 0x5134a6 0x549e0e 0x4bcb19 0x5134a6 0x549e0e 0x4bcb19\n","Summarize dataset:  48% 26/54 [00:19<00:13,  2.05it/s, Describe variable:totals.totalTransactionRevenue]^C\n"]}]},{"cell_type":"markdown","source":["### Step 5: Data Prep for Modeling\n","\n","Goal:\n","- Create 4 datasets as inputs for 4 models\n","- Prep should include:\n","  * Column Dropping\n","  * Column Encoding\n","\n","The 4 datasets for each model should be:\n","- A1- Likelyhood to convert data set (Visitors) (Assigned: @Fred)\n","- B2- Complex clustering data set (Visitors) (Assigned: @Fred)\n","- B1- RFM data set (Assigned: @Fred)\n","- A2- Returning customers data set (Assigned: @Idris)\n","- [Optional] A3- Attribution model data set (Assigned: @Tia)\n"],"metadata":{"id":"dgI0faFXVf6x"}},{"cell_type":"code","source":["!python data_prep.py \\\n","  --input_file ../datasets/cleaned_dataset.csv \\\n","  --output_directory ../datasets/model_files"],"metadata":{"id":"HHsgR42lWKmM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652548692310,"user_tz":240,"elapsed":7088,"user":{"displayName":"Idris Hanafi","userId":"08993226175925256732"}},"outputId":"23a88137-a477-4436-ae0b-6eaa4e14aa6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n","../datasets/cleaned_dataset.csv ../datasets/model_files\n","2016-08-01 00:00:00 succesfully transformed to a datime object\n","Divided by 10^6\n","Transformations being made\n","1 date NO CHANGE\n","2 fullVisitorId NO CHANGE\n","3 socialEngagementType fillnan\n","3 socialEngagementType binary\n","3 socialEngagementType int64\n","4 channelGrouping one_hot drop\n","5 totals.hits int64\n","5 totals.hits NO CHANGE\n","6 totals.pageviews fillnan\n","7 totals.timeOnSite fillnan\n","8 totals.transactions fillnan\n","9 totals.newVisits fillnan\n","9 totals.newVisits int64\n","10 hits.eCommerceAction.action_type int64\n","10 hits.eCommerceAction.action_type NO CHANGE\n","11 totals.bounces fillnan\n","11 totals.bounces int64\n","0.1183562197092084\n","12 geoNetwork.country geoNetwork.country_woe woe\n","12 geoNetwork.country drop\n","0.1183562197092084\n","13 trafficSource.source trafficSource.source_woe woe\n","13 trafficSource.source drop\n","14 trafficSource.medium one_hot drop\n","15 trafficSource.isTrueDirect fillnan\n","cat_code trafficSource.isTrueDirect\n","0.1183562197092084\n","16 device.browser device.browser_woe woe\n","16 device.browser drop\n","17 device.operatingSystem one_hot drop\n","18 device.deviceCategory one_hot drop\n","19 hits.type drop\n","20 hits.hour drop\n","21 hits.minute drop\n","22 Monetary fillnan\n","23 Recency NO CHANGE\n","24 Frequency NO CHANGE\n","25 buyers NO CHANGE\n","26 repurchasers int64\n","26 repurchasers NO CHANGE\n","succesfully exporting changes file to csv\n","succesfully exporting both A1_B2 files to csv\n","succesfully exporting A2 to csv\n","succesfully exporting B1 rfm to csv\n"]}]},{"cell_type":"markdown","source":["### Step 6: Data Visualization\n","\n","Goal:\n","- Visualize the model datasets.\n","\n","To the dashboard_files file:\n","- Visualizations\n","- EDA\n","- Describing Data\n","- Histograms\n","- Dashboarding ([Pandas Profiling](https://github.com/ydataai/pandas-profiling))\n","\n","Assigned: \n","- [x] @Tia\n","- @ Tia run again later to fix the names before pushing to GitHub\n"],"metadata":{"id":"qml8pOYAdHq7"}},{"cell_type":"code","source":["!python data_vis.py \\\n","  --input_directory ../datasets/model_files/ \\\n","  --output_directory ../datasets/dashboard_files/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653005544956,"user_tz":420,"elapsed":187886,"user":{"displayName":"Tia Burton","userId":"09352393735441630552"}},"outputId":"cdd1358b-bba8-497a-ec1c-84cb39b5b2db","id":"NUz3Fb2YdHq8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Summarize dataset: 100% 34/34 [00:06<00:00,  5.61it/s, Completed]\n","Generate report structure: 100% 1/1 [00:03<00:00,  3.10s/it]\n","Render HTML: 100% 1/1 [00:00<00:00,  1.25it/s]\n","Export report to file: 100% 1/1 [00:00<00:00, 72.90it/s]\n","Summarize dataset: 100% 29/29 [00:05<00:00,  4.96it/s, Completed]\n","Generate report structure: 100% 1/1 [00:04<00:00,  4.64s/it]\n","Render HTML: 100% 1/1 [00:00<00:00,  1.54it/s]\n","Export report to file: 100% 1/1 [00:00<00:00, 74.63it/s]\n","Summarize dataset: 100% 203/203 [01:04<00:00,  3.17it/s, Completed]\n","Generate report structure: 100% 1/1 [00:19<00:00, 19.47s/it]\n","Render HTML: 100% 1/1 [00:05<00:00,  5.91s/it]\n","Export report to file: 100% 1/1 [00:00<00:00, 22.47it/s]\n","Summarize dataset: 100% 203/203 [00:47<00:00,  4.24it/s, Completed]\n","Generate report structure: 100% 1/1 [00:19<00:00, 19.36s/it]\n","Render HTML: 100% 1/1 [00:06<00:00,  6.04s/it]\n","Export report to file: 100% 1/1 [00:00<00:00, 22.96it/s]\n"]}]},{"cell_type":"markdown","source":["# Modeling Pipeline\n","\n","Goal:\n","- @All test out our input dataset against our models and discuss results\n","\n","For each model, it should save:\n","1. Train the model and save the model\n","2. Model Inference and save results (visualization, csv, etc.)"],"metadata":{"id":"OIhutrPtVtLF"}},{"cell_type":"markdown","source":["## Supervised Learning (A1): Conversion Likelihood Analysis\n","\n","Goal: Identify whether a user is a potential customer"],"metadata":{"id":"KnPJi5A_r6UK"}},{"cell_type":"code","source":["!python a1_model_training.py \\\n","  --input_dataset ../datasets/model_files/A1_B2_data.csv \\\n","  --output_directory ../models/spark_models/ \\\n","  --output_result_directory ../results/ \\\n","  --output_visualization_directory ../visualizations/"],"metadata":{"id":"PY4rF0PmsC8S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653937145597,"user_tz":420,"elapsed":27546,"user":{"displayName":"Tia Burton","userId":"09352393735441630552"}},"outputId":"6254aff2-84bd-4290-e60e-eefbc45fec83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n","  defaults = yaml.load(f)\n","../datasets/model_files/A1_B2_data.csv ../models/spark_models/ ../visualizations/\n","WARNING: An illegal reflective access operation has occurred\n","WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.7/dist-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n","WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n","WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","WARNING: All illegal access operations will be denied in a future release\n","Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","22/05/30 18:58:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","Traceback (most recent call last):\n","  File \"a1_model_training.py\", line 274, in <module>\n","    unbalanced_df, downsample_df, random_df = return_samples(train_spark)\n","  File \"a1_model_training.py\", line 59, in return_samples\n","    downsample_df = downsampling(unbalanced_df)\n","  File \"a1_model_training.py\", line 64, in downsampling\n","    label_balance = unbalanced_df.groupBy('label').count().withColumnRenamed('count','unbalanced_count')\n","NameError: name 'unbalanced_df' is not defined\n"]}]},{"cell_type":"code","source":["!python a1_model_inference.py \\\n","  --input_models_directory ../models/model_files/<your_input_model_directory> \\\n","  --output_result_directory ../results/ \\\n","  --output_visualization_directory ../visualizations/"],"metadata":{"id":"j5MJIWSjsE9D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653931066660,"user_tz":420,"elapsed":183,"user":{"displayName":"Tia Burton","userId":"09352393735441630552"}},"outputId":"871f6f3b-a65b-4a69-cdb0-c9542144a71e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: your_input_model_directory: No such file or directory\n"]}]},{"cell_type":"markdown","source":["## Supervised Learning (A2): Repurchaser Analysis\n","\n","Goal: Identify whether a user is a potential repurchaser or not, i.e. a potential returning customer"],"metadata":{"id":"ZudVh2sCoxlt"}},{"cell_type":"code","source":["!python a2_model_training.py \\\n","  --input_dataset ../datasets/model_files/A2_return_data.csv \\\n","  --output_directory ../models/ \\\n","  --output_result_directory ../results/ \\\n","  --output_visualization_directory ../visualizations/"],"metadata":{"id":"7PD_L7v8o99u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653935477124,"user_tz":240,"elapsed":36101,"user":{"displayName":"Idris Hanafi","userId":"08993226175925256732"}},"outputId":"0ce0b907-d516-4955-8a1a-797e9c5752ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["../datasets/model_files/A2_return_data.csv ../models/ ../results/ ../visualizations/\n","Beginning Logistic Regression\n","Beginning SVC\n","Beginning KNN\n","Beginning Decision Trees\n","Beginning Random Forests\n","<Figure size 2000x2000 with 2 Axes>\n","<Figure size 800x300 with 2 Axes>\n","<Figure size 640x480 with 0 Axes>\n","<Figure size 2400x800 with 1 Axes>\n","Frequency 0.8626647389272503\n","channelGrouping_Organic Search 0.01817720718509018\n","Monetary 0.016707180105817145\n","channelGrouping_Direct 0.012295209751090544\n","totals.timeOnSite 0.011119207277461903\n","totals.pageviews 0.010012481758793837\n","channelGrouping_Referral 0.009129065315048729\n","Recency 0.008044090914501987\n","channelGrouping_Paid Search 0.005761877998246554\n","trafficSource.medium_cpm 0.004599542913452809\n","trafficSource.medium_referral 0.004566293966799045\n","hits.hour_ordinal 0.00455522685965397\n","geoNetwork.country_woe 0.0043395415727116166\n","device.operatingSystem_Linux 0.004314187243082622\n","totals.hits 0.003972729623929231\n","device.operatingSystem_iOS 0.0028149935408655702\n","trafficSource.isTrueDirect_code 0.0027099526439167887\n","device.operatingSystem_Windows 0.002709935997910708\n","totals.newVisits 0.0023084972866095387\n","device.operatingSystem_Macintosh 0.0021645335943932475\n","device.deviceCategory_mobile 0.001842222319475965\n","device.operatingSystem_Chrome OS 0.0018402330933454483\n","device.browser_woe 0.0011661920099493583\n","device.operatingSystem_Android 0.0009235713224544305\n","trafficSource.medium_organic 0.000597364606995608\n","trafficSource.source_woe 0.0003632733255788857\n","hits.eCommerceAction.action_type 0.00030064884557396923\n","socialEngagementType 0.0\n","totals.transactions 0.0\n","totals.bounces 0.0\n","channelGrouping_Display 0.0\n","channelGrouping_Social 0.0\n","trafficSource.medium_affiliate 0.0\n","trafficSource.medium_cpc 0.0\n","device.operatingSystem_BlackBerry 0.0\n","device.operatingSystem_Firefox OS 0.0\n","device.operatingSystem_Nintendo Wii 0.0\n","device.operatingSystem_Samsung 0.0\n","device.operatingSystem_Windows Phone 0.0\n","device.operatingSystem_Xbox 0.0\n","device.deviceCategory_tablet 0.0\n","buyers 0.0\n","Frequency 0.8626647389272503\n","channelGrouping_Organic Search 0.01817720718509018\n","Monetary 0.016707180105817145\n","channelGrouping_Direct 0.012295209751090544\n","totals.timeOnSite 0.011119207277461903\n","totals.pageviews 0.010012481758793837\n","Beginning Logistic Regression\n","Beginning SVC\n","Beginning KNN\n","Beginning Decision Trees\n","Beginning Random Forests\n","<Figure size 640x480 with 0 Axes>\n","<Figure size 2400x800 with 1 Axes>\n","Frequency 0.8626647389272503\n","channelGrouping_Organic Search 0.01817720718509018\n","Monetary 0.016707180105817145\n","channelGrouping_Direct 0.012295209751090544\n","totals.timeOnSite 0.011119207277461903\n","totals.pageviews 0.010012481758793837\n","ROC AUC Score 0.9218260145530899\n","F1 Score 0.9226932668329177\n"]}]},{"cell_type":"markdown","source":["## Unsupervised (B1 and B2) Model (Training and Model Inference) "],"metadata":{"id":"Zkt5qPEVs5nX"}},{"cell_type":"code","source":["!python B2_B1_model_training.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uEklWhW1s2DQ","executionInfo":{"status":"ok","timestamp":1653510104454,"user_tz":240,"elapsed":19516,"user":{"displayName":"Idris Hanafi","userId":"08993226175925256732"}},"outputId":"56b6778a-f7ff-4df4-9646-bb6b0f97b9bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0- importing packages\n","1- downloading file\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","2- rebalancing classes\n","3- scaling df\n","3- scaling df\n","4.1. returning spree chart\n","4.1. returning pca heatmap\n","4.1. processing and saving pca balanced class\n","4.1. returning pca heatmap\n","4.1. processing and saving pca imbalanced data set\n","4.2- downloading famd df, model and visualizations\n","5.1- downloading kmeans scores\n","5.1- downloading kmeans scores\n","5.1- downloading kmeans scores\n","5.1- downloading kmeans scores\n","error with saving DF as image\n","<Figure size 800x300 with 2 Axes>\n","<Figure size 1400x400 with 1 Axes>\n","<Figure size 4000x100 with 2 Axes>\n","<Figure size 4000x100 with 2 Axes>\n","<Figure size 1800x400 with 4 Axes>\n","5.1- returning elbow scores\n","5.1- downloading elbow scores, silhouette and score tables\n","error with saving DF as image\n","5.2- pca returning groupes and pca_transformed\n","5.2- returning pca/kmeans full heat map\n","5.2 downloading biplot clustering visualization\n","5.1- downloading kmeans scores\n","5.1- downloading kmeans scores\n","5.1- downloading kmeans scores\n","5.1- downloading kmeans scores\n","error with saving DF as image\n","<Figure size 1800x400 with 4 Axes>\n","5.1- returning elbow scores\n","5.1- downloading elbow scores, silhouette and score tables\n","6. download kmedoids df, model and img\n","6. downloading kmedoids scores\n","{'silhouette': 0.4, 'bouldin': 0.79}\n","7. downloading dbscan scores\n","7. downloading dbscan model and visualization\n","7. processing model, dbscan visualization and df\n","8- importando rfm csv file\n","3- scaling df\n","8- downloading RFM groupe\n","8- returning RFM groupe\n"]}]}]}